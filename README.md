# Demo RAG para Marketing

Esta aplicaci√≥n demuestra el poder de **Retrieval-Augmented Generation (RAG)** para mejorar las respuestas de LLMs, especialmente cuando se trata de informaci√≥n especializada o que no est√° en su entrenamiento base.

## üöÄ Caracter√≠sticas

- Compara respuestas de un modelo RAG vs un LLM tradicional
- Muestra los documentos recuperados para la generaci√≥n de respuestas
- Interfaz intuitiva con Streamlit
- Ejemplos predefinidos para demostrar los beneficios de RAG
- Utiliza datos sint√©ticos de marketing con informaci√≥n ficticia pero plausible

## ‚ú® Beneficios de RAG demostrados

1. **Mayor precisi√≥n factual**: RAG proporciona respuestas basadas en la documentaci√≥n espec√≠fica
2. **Menor alucinaci√≥n**: El modelo tiene menos tendencia a inventar informaci√≥n
3. **Transparencia**: Se muestran las fuentes utilizadas para generar la respuesta
4. **Informaci√≥n espec√≠fica**: Acceso a datos que no est√°n en el entrenamiento del LLM

## üîß Requisitos

- Python 3.12
- Una clave API de Anthropic y/o OpenAI (seg√∫n el proveedor que quieras usar)

## üìã Instalaci√≥n

1. Clona este repositorio

2. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

3. Configura tus claves API en el archivo `.env`:
   ```bash
   cp .env.template .env
   # Edita el archivo .env con las claves API de los proveedores que vayas a usar
   ```

## üöÄ Ejecuci√≥n

Para ejecutar la aplicaci√≥n, sigue estos pasos:

1. Procesa los documentos y crea embeddings:
   ```bash
   python indexador.py
   ```

2. Ejecuta la aplicaci√≥n Streamlit:
   ```bash
   streamlit run app.py
   ```

3. Abre tu navegador en: http://localhost:8501

## üìÅ Estructura del proyecto

- `app.py`: Aplicaci√≥n principal con interfaz Streamlit
- `rag.py`: Core RAG logic, invocado desde `app.py`
- `indexador.py`: Procesamiento y creaci√≥n de embeddings para documentos
- `requirements.txt`: Dependencias del proyecto
- `.env.template`: Plantilla para configuraci√≥n de API keys
- `data/`: Directorio que contiene documentos JSON prefabricados con informaci√≥n de marketing
  - `documentos_marketing.json`: Archivo combinado con todos los documentos
  - `doc_001.json` a `doc_020.json`: Documentos individuales con temas de marketing espec√≠ficos

## How it works

1. **Data**: La aplicaci√≥n utiliza documentos prefabricados con informaci√≥n ficticia de marketing (conceptos inventados, metodolog√≠as ficticias, casos de estudio)
2. **Indexing**: Procesa los documentos JSON y crea embeddings con SentenceTransformers
3. **Retrieval**: Dada una consulta, encuentra los documentos m√°s relevantes
4. **Generation**: Utiliza el mismo modelo LLM (Anthropic o OpenAI) para dos tareas:
   - Generar respuestas con contexto recuperado (RAG)
   - Generar respuestas sin contexto adicional (LLM b√°sico)
5. **Comparison**: Presenta ambas respuestas lado a lado y muestra los documentos utilizados

## üîÑ Selecci√≥n de proveedor LLM

La aplicaci√≥n permite elegir entre dos proveedores de modelos de lenguaje:

- **Anthropic Claude**: Modelos Claude optimizados para tareas de generaci√≥n de texto
- **OpenAI GPT**: Modelos GPT con capacidades avanzadas de procesamiento de lenguaje

Simplemente selecciona tu proveedor preferido en la barra lateral de la aplicaci√≥n. La aplicaci√≥n utilizar√° la clave API correspondiente configurada en tu archivo `.env`.

## Consideraciones de implementaci√≥n

- Los datos son sint√©ticos y creados espec√≠ficamente para demostrar la diferencia entre RAG y LLMs tradicionales.
- La aplicaci√≥n mantiene el almac√©n de documentos en memoria.
- Los modelos predeterminados son `claude-3-haiku-20240307` para Anthropic y `gpt-4o-mini` para OpenAI, pero pueden modificarse en el c√≥digo.
